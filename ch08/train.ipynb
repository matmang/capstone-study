{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7524fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from deep_conv.ipynb\n",
      "train loss:2.280654120173991\n",
      "=== epoch:1, train acc:0.16, test acc:0.176 ===\n",
      "train loss:2.264164535500765\n",
      "train loss:2.2685017856990055\n",
      "train loss:2.273368154442337\n",
      "train loss:2.2781440715500803\n",
      "train loss:2.2793353365941678\n",
      "train loss:2.2380124545062614\n",
      "train loss:2.2569705957622297\n",
      "train loss:2.2693133531537453\n",
      "train loss:2.247895368733018\n",
      "train loss:2.2502170392197796\n",
      "train loss:2.257181186893443\n",
      "train loss:2.231591929707495\n",
      "train loss:2.2120135743036213\n",
      "train loss:2.1723484380745326\n",
      "train loss:2.2118010915003508\n",
      "train loss:2.1704424181592086\n",
      "train loss:2.1327924160082192\n",
      "train loss:2.149736251849061\n",
      "train loss:2.1516699018494436\n",
      "train loss:2.1111024905334927\n",
      "train loss:2.064957548644848\n",
      "train loss:2.003862187195541\n",
      "train loss:1.9902734268873812\n",
      "train loss:2.1155780447417136\n",
      "train loss:1.8996013955223856\n",
      "train loss:1.843012105318213\n",
      "train loss:2.0306548547405505\n",
      "train loss:1.735131146608297\n",
      "train loss:1.8198733817955095\n",
      "train loss:1.7143459868859492\n",
      "train loss:1.773010647588693\n",
      "train loss:1.5855659785744312\n",
      "train loss:1.914699729382214\n",
      "train loss:1.8349319039215584\n",
      "train loss:1.9152090837470968\n",
      "train loss:1.8586300338631594\n",
      "train loss:1.7915306437381293\n",
      "train loss:1.817085744508538\n",
      "train loss:1.8005085065760058\n",
      "train loss:1.6935097682637923\n",
      "train loss:1.5872100630474189\n",
      "train loss:1.6474973474653527\n",
      "train loss:1.785575255699131\n",
      "train loss:1.6327017225023681\n",
      "train loss:1.7343609997304088\n",
      "train loss:1.6184158651395741\n",
      "train loss:1.7687847419433718\n",
      "train loss:1.568776953645198\n",
      "train loss:1.5235262697854772\n",
      "train loss:1.5832585041808855\n",
      "train loss:1.778574473246862\n",
      "train loss:1.6669628216882952\n",
      "train loss:1.725404290185534\n",
      "train loss:1.6898670129356046\n",
      "train loss:1.5613033213888536\n",
      "train loss:1.640312853618277\n",
      "train loss:1.569158814345063\n",
      "train loss:1.6683509974213582\n",
      "train loss:1.6933936278985837\n",
      "train loss:1.5913284569917079\n",
      "train loss:1.4638334206554051\n",
      "train loss:1.6555584133042112\n",
      "train loss:1.5013592867501955\n",
      "train loss:1.6795000338178234\n",
      "train loss:1.6005990431818582\n",
      "train loss:1.6726442853628185\n",
      "train loss:1.5039380518223615\n",
      "train loss:1.5817048717363047\n",
      "train loss:1.5952454796844129\n",
      "train loss:1.4743875965810043\n",
      "train loss:1.7359207392093083\n",
      "train loss:1.54247115787418\n",
      "train loss:1.5178511035785416\n",
      "train loss:1.3830200041245064\n",
      "train loss:1.3698637255129946\n",
      "train loss:1.324248103498942\n",
      "train loss:1.3894610982132425\n",
      "train loss:1.6071113351596014\n",
      "train loss:1.6801204548360815\n",
      "train loss:1.5923978373016763\n",
      "train loss:1.3966718277075854\n",
      "train loss:1.614574285949448\n",
      "train loss:1.2901775981463957\n",
      "train loss:1.5464363895898359\n",
      "train loss:1.4557473844473896\n",
      "train loss:1.5098094827517567\n",
      "train loss:1.3878793090629062\n",
      "train loss:1.4872226494816994\n",
      "train loss:1.5325439832154621\n",
      "train loss:1.4696025708979974\n",
      "train loss:1.5262029984373382\n",
      "train loss:1.429743426531263\n",
      "train loss:1.429018796859207\n",
      "train loss:1.4603447745499494\n",
      "train loss:1.2689589184704935\n",
      "train loss:1.4141296413575\n",
      "train loss:1.325338902752283\n",
      "train loss:1.334005371977296\n",
      "train loss:1.319647232302455\n",
      "train loss:1.2766008875029575\n",
      "train loss:1.5604278922479617\n",
      "train loss:1.4036097648687778\n",
      "train loss:1.5888804985570388\n",
      "train loss:1.2921016512973211\n",
      "train loss:1.3332841096061911\n",
      "train loss:1.4257191630463637\n",
      "train loss:1.3399736557070627\n",
      "train loss:1.3073160924039993\n",
      "train loss:1.3247792729100798\n",
      "train loss:1.551950108277149\n",
      "train loss:1.4345929479762105\n",
      "train loss:1.412913337683573\n",
      "train loss:1.2942371007748519\n",
      "train loss:1.3606226002304707\n",
      "train loss:1.48014792233907\n",
      "train loss:1.4360829795104066\n",
      "train loss:1.3657018412736768\n",
      "train loss:1.4531515398907036\n",
      "train loss:1.321236636469949\n",
      "train loss:1.3312951646251703\n",
      "train loss:1.3068793528612954\n",
      "train loss:1.2397792218397814\n",
      "train loss:1.271181506338977\n",
      "train loss:1.3354977178542073\n",
      "train loss:1.3571989292061377\n",
      "train loss:1.4512629142926614\n",
      "train loss:1.3637991019140683\n",
      "train loss:1.5010727835694189\n",
      "train loss:1.45722280800379\n",
      "train loss:1.3228413884517298\n",
      "train loss:1.2944512322250308\n",
      "train loss:1.4491507271553048\n",
      "train loss:1.2049161172530767\n",
      "train loss:1.431562730975946\n",
      "train loss:1.3244485861591238\n",
      "train loss:1.5445664020967402\n",
      "train loss:1.228388732890676\n",
      "train loss:1.2484426482793523\n",
      "train loss:1.1700854741740414\n",
      "train loss:1.25299919065829\n",
      "train loss:1.3428198711898554\n",
      "train loss:1.3079452337603132\n",
      "train loss:1.2383608239614963\n",
      "train loss:1.3550674930025124\n",
      "train loss:1.1259501845939712\n",
      "train loss:1.3400189369399198\n",
      "train loss:1.2133932686626492\n",
      "train loss:1.2874265692487343\n",
      "train loss:1.2612445972085553\n",
      "train loss:1.4526335423212742\n",
      "train loss:1.3682307115439791\n",
      "train loss:1.2205612614119432\n",
      "train loss:1.2124493958133065\n",
      "train loss:1.4242298010618304\n",
      "train loss:1.3343392757970454\n",
      "train loss:1.3825179140691939\n",
      "train loss:1.2096226377098944\n",
      "train loss:1.3464203199248548\n",
      "train loss:1.0921571855530496\n",
      "train loss:1.2689497805334786\n",
      "train loss:1.3874644296811878\n",
      "train loss:1.3698682207262518\n",
      "train loss:1.2711610805085332\n",
      "train loss:1.127676232511792\n",
      "train loss:1.1571782459125388\n",
      "train loss:1.123135018440029\n",
      "train loss:1.3327423709566757\n",
      "train loss:1.51180117018022\n",
      "train loss:1.3593859193582276\n",
      "train loss:1.22085789819209\n",
      "train loss:1.1595879467212227\n",
      "train loss:1.3030559173884968\n",
      "train loss:1.0579252564834496\n",
      "train loss:1.035295107583175\n",
      "train loss:1.1804680523557252\n",
      "train loss:1.22540452220402\n",
      "train loss:1.3116565428979627\n",
      "train loss:1.1863563930280958\n",
      "train loss:1.2551667371907498\n",
      "train loss:1.2700378951820643\n",
      "train loss:1.4706923421461247\n",
      "train loss:1.3307114158627078\n",
      "train loss:1.3229909293514601\n",
      "train loss:1.3249558478210284\n",
      "train loss:1.2390763634724298\n",
      "train loss:1.22650689464555\n",
      "train loss:1.1803645783861718\n",
      "train loss:1.1008064075612045\n",
      "train loss:1.216050177656335\n",
      "train loss:1.2412102859720147\n",
      "train loss:1.2403894248701115\n",
      "train loss:1.2280165782146124\n",
      "train loss:1.2148883332661318\n",
      "train loss:1.2538319663141673\n",
      "train loss:1.1277487882724444\n",
      "train loss:1.362117911700738\n",
      "train loss:1.1390179476618616\n",
      "train loss:1.3308577673370354\n",
      "train loss:1.1970734612336313\n",
      "train loss:1.1843686185997668\n",
      "train loss:1.1593521203253068\n",
      "train loss:1.250240346316493\n",
      "train loss:1.3555059068968047\n",
      "train loss:1.2027354156649994\n",
      "train loss:1.1448903856364745\n",
      "train loss:1.098497951977754\n",
      "train loss:1.2773921532108634\n",
      "train loss:1.138705293537305\n",
      "train loss:1.130071778472808\n",
      "train loss:1.0435864421311551\n",
      "train loss:1.4408462687377743\n",
      "train loss:1.3304137675424914\n",
      "train loss:1.358488834986978\n",
      "train loss:1.1876349030436841\n",
      "train loss:1.254610781797392\n",
      "train loss:1.2382150884584049\n",
      "train loss:1.1654948153543343\n",
      "train loss:1.2556981284590931\n",
      "train loss:1.092639618074636\n",
      "train loss:1.2657849668164314\n",
      "train loss:1.2415634039252528\n",
      "train loss:1.0553131529458921\n",
      "train loss:1.1007696786474157\n",
      "train loss:1.2217416152996607\n",
      "train loss:0.9838834742468591\n",
      "train loss:1.08505075434131\n",
      "train loss:1.1947853045287673\n",
      "train loss:1.2724644754100485\n",
      "train loss:1.298335607510426\n",
      "train loss:1.0862758624294315\n",
      "train loss:1.1051268004943855\n",
      "train loss:1.3291044236778964\n",
      "train loss:1.229245745945927\n",
      "train loss:1.2145134600563858\n",
      "train loss:1.0904226447983234\n",
      "train loss:1.0337297780698371\n",
      "train loss:1.0957582699122665\n",
      "train loss:1.2962435316653558\n",
      "train loss:1.2433317912931554\n",
      "train loss:1.0610537785671588\n",
      "train loss:1.1903167689023846\n",
      "train loss:1.082906410936794\n",
      "train loss:1.1472954638511994\n",
      "train loss:1.0921211805186433\n",
      "train loss:1.0280908355294478\n",
      "train loss:0.9082509660320994\n",
      "train loss:1.264257769042705\n",
      "train loss:0.9192280178710344\n",
      "train loss:1.0745971558443381\n",
      "train loss:1.1089234635470897\n",
      "train loss:1.1626899004440612\n",
      "train loss:1.2134139234563441\n",
      "train loss:1.4013304460771423\n",
      "train loss:1.1722235531458691\n",
      "train loss:1.1324669014892672\n",
      "train loss:1.1786951762197788\n",
      "train loss:1.162581621106101\n",
      "train loss:1.3804394830111955\n",
      "train loss:1.2472833977850923\n",
      "train loss:0.9990676172913413\n",
      "train loss:1.115089384526199\n",
      "train loss:1.1737839212494157\n",
      "train loss:1.2752485004309988\n",
      "train loss:1.2742865871754956\n",
      "train loss:1.4007713808304316\n",
      "train loss:1.3182807019065441\n",
      "train loss:1.0459617102650705\n",
      "train loss:1.0790534314500466\n",
      "train loss:1.094444028886906\n",
      "train loss:1.242218238953174\n",
      "train loss:0.9769599339227706\n",
      "train loss:1.162992457108726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1805301031991795\n",
      "train loss:1.0052811218247373\n",
      "train loss:1.1111195829080538\n",
      "train loss:1.059639507162986\n",
      "train loss:1.05865303125184\n",
      "train loss:1.143402418566121\n",
      "train loss:1.1208401850876557\n",
      "train loss:1.1798458190519292\n",
      "train loss:1.1616110016318328\n",
      "train loss:1.1208823486679675\n",
      "train loss:1.217143536776755\n",
      "train loss:1.02414360864398\n",
      "train loss:1.0516701986294945\n",
      "train loss:1.059647019882724\n",
      "train loss:0.8824303822365803\n",
      "train loss:0.971687163334536\n",
      "train loss:1.073388454532887\n",
      "train loss:1.0359831661669363\n",
      "train loss:1.0222670868467738\n",
      "train loss:1.0238211221112814\n",
      "train loss:1.37494486910078\n",
      "train loss:1.3585638109808176\n",
      "train loss:1.205678465219028\n",
      "train loss:1.1345845947914481\n",
      "train loss:1.1420979057801761\n",
      "train loss:1.0988379796692411\n",
      "train loss:1.2330854896554861\n",
      "train loss:1.068490491725277\n",
      "train loss:1.0358305488477633\n",
      "train loss:1.138099850630371\n",
      "train loss:1.1709460684381519\n",
      "train loss:1.171818825993538\n",
      "train loss:1.0602045568860603\n",
      "train loss:1.2125543147522257\n",
      "train loss:1.3539328453874637\n",
      "train loss:1.047762230653504\n",
      "train loss:1.0289541453764282\n",
      "train loss:1.0664786424353616\n",
      "train loss:1.1144816208567812\n",
      "train loss:1.0672860585512551\n",
      "train loss:1.056358896509214\n",
      "train loss:1.0628427927403439\n",
      "train loss:1.158904168760048\n",
      "train loss:1.087283670314733\n",
      "train loss:1.0743710868762018\n",
      "train loss:0.9720559232995669\n",
      "train loss:0.8903137211627642\n",
      "train loss:1.0769879099533917\n",
      "train loss:1.070237405047684\n",
      "train loss:1.1786993061857132\n",
      "train loss:1.2212948738742058\n",
      "train loss:1.1516794520397127\n",
      "train loss:1.1126495052200909\n",
      "train loss:1.067418238997765\n",
      "train loss:1.359388970961233\n",
      "train loss:1.016181554898752\n",
      "train loss:1.0902127625918807\n",
      "train loss:1.1712204151149692\n",
      "train loss:1.3449747076989116\n",
      "train loss:1.2224947141638007\n",
      "train loss:1.0774751897677748\n",
      "train loss:1.2419571162254857\n",
      "train loss:1.1928919338734438\n",
      "train loss:1.0911986281303385\n",
      "train loss:1.1445301597978785\n",
      "train loss:1.0528484957191657\n",
      "train loss:1.0373308738326321\n",
      "train loss:1.001226688793772\n",
      "train loss:1.2726104010102521\n",
      "train loss:1.1739144674530186\n",
      "train loss:1.0592136319494176\n",
      "train loss:1.1830445033157124\n",
      "train loss:1.0289395433331798\n",
      "train loss:1.2685332674738512\n",
      "train loss:1.360561054070473\n",
      "train loss:1.2742235372916417\n",
      "train loss:1.186209812406296\n",
      "train loss:1.1769464375470977\n",
      "train loss:0.9528365678514994\n",
      "train loss:1.0940463370242235\n",
      "train loss:1.226967025399497\n",
      "train loss:1.0498653721075484\n",
      "train loss:1.1308536837187773\n",
      "train loss:1.1422002835094496\n",
      "train loss:1.0959745315301594\n",
      "train loss:1.1925525125021466\n",
      "train loss:1.0604195748605927\n",
      "train loss:1.1945346592580026\n",
      "train loss:1.003065237066281\n",
      "train loss:1.0708884485864563\n",
      "train loss:1.1313317281023019\n",
      "train loss:1.3205747082424082\n",
      "train loss:1.1054142215223306\n",
      "train loss:1.2628944108339133\n",
      "train loss:1.2285214471363861\n",
      "train loss:1.0699085651913556\n",
      "train loss:1.1767418435038046\n",
      "train loss:1.3511148688542105\n",
      "train loss:0.9919648947350409\n",
      "train loss:1.1474653296825337\n",
      "train loss:1.0894627283816463\n",
      "train loss:1.0107668850180156\n",
      "train loss:1.3413845690305675\n",
      "train loss:1.261561243507181\n",
      "train loss:0.962910746216143\n",
      "train loss:1.1309285067252004\n",
      "train loss:1.0294578851490295\n",
      "train loss:1.1418481631938782\n",
      "train loss:1.1078628634412668\n",
      "train loss:1.0994661848635325\n",
      "train loss:1.2061912695823336\n",
      "train loss:1.1583718299423935\n",
      "train loss:0.9731671331081428\n",
      "train loss:1.1429163459271072\n",
      "train loss:1.3282420427537043\n",
      "train loss:0.9842019540793134\n",
      "train loss:1.0540432120419072\n",
      "train loss:0.9548660581884336\n",
      "train loss:1.1402977598070363\n",
      "train loss:1.0644867287942377\n",
      "train loss:1.1558851152221856\n",
      "train loss:1.1368245826558419\n",
      "train loss:1.0780496723955175\n",
      "train loss:1.078128038492471\n",
      "train loss:1.2149617382589672\n",
      "train loss:1.064524502328184\n",
      "train loss:1.0436285237952958\n",
      "train loss:1.098280753588632\n",
      "train loss:1.1282168609650727\n",
      "train loss:1.0459286343277658\n",
      "train loss:1.084222529693607\n",
      "train loss:1.1503234447019373\n",
      "train loss:1.1091557117002508\n",
      "train loss:1.2132493097334307\n",
      "train loss:1.08356918873045\n",
      "train loss:1.1827230731674527\n",
      "train loss:1.15195360135422\n",
      "train loss:0.963952270847412\n",
      "train loss:1.0067587264479017\n",
      "train loss:1.0327683372527177\n",
      "train loss:1.0243636549345962\n",
      "train loss:1.0931802232531718\n",
      "train loss:0.9880394654798059\n",
      "train loss:1.0533933074890551\n",
      "train loss:1.2254844459837109\n",
      "train loss:1.0819824474287716\n",
      "train loss:1.1397414640207886\n",
      "train loss:1.0002976147451073\n",
      "train loss:0.933755871053287\n",
      "train loss:1.1113522435929604\n",
      "train loss:1.246644641529906\n",
      "train loss:1.0797947811857354\n",
      "train loss:1.116549113233531\n",
      "train loss:1.0462108893822133\n",
      "train loss:0.9606951454498133\n",
      "train loss:0.8746685053769039\n",
      "train loss:1.0942962168372097\n",
      "train loss:1.2565100756066554\n",
      "train loss:1.0724883296027756\n",
      "train loss:1.119200361525493\n",
      "train loss:1.278143913602294\n",
      "train loss:1.1986184582161095\n",
      "train loss:1.0940273113605579\n",
      "train loss:1.1541948755251403\n",
      "train loss:0.9584148390602423\n",
      "train loss:1.1900813585748597\n",
      "train loss:1.058753313908838\n",
      "train loss:0.9997028720646027\n",
      "train loss:1.0347969898594698\n",
      "train loss:1.19917806199786\n",
      "train loss:1.1916240862159042\n",
      "train loss:1.1362417785738745\n",
      "train loss:0.9493432618338501\n",
      "train loss:1.008509039574551\n",
      "train loss:1.1185626721973596\n",
      "train loss:0.8538801733029682\n",
      "train loss:1.2052312110738808\n",
      "train loss:1.18809715125703\n",
      "train loss:1.161968843330458\n",
      "train loss:1.195473223794648\n",
      "train loss:1.1234916697085213\n",
      "train loss:1.0397210214526282\n",
      "train loss:0.9972091410878616\n",
      "train loss:1.1951265186656144\n",
      "train loss:1.011417661585812\n",
      "train loss:1.0907747698276975\n",
      "train loss:1.0989255242034675\n",
      "train loss:1.1320819036936371\n",
      "train loss:1.0684804310994664\n",
      "train loss:1.044448071172408\n",
      "train loss:1.0447861037280008\n",
      "train loss:1.0710019078774422\n",
      "train loss:1.1885733333020576\n",
      "train loss:1.0761650479562361\n",
      "train loss:1.1347309766968219\n",
      "train loss:1.025629614777911\n",
      "train loss:1.1881009257069364\n",
      "train loss:1.156072819847253\n",
      "train loss:1.1807117163195946\n",
      "train loss:1.1877386261947178\n",
      "train loss:1.1770828397822828\n",
      "train loss:1.197171309577371\n",
      "train loss:0.8655182666473503\n",
      "train loss:1.0931661060955786\n",
      "train loss:1.0795763264819889\n",
      "train loss:1.2049014819322454\n",
      "train loss:1.2965284677997269\n",
      "train loss:1.0270740950825326\n",
      "train loss:1.0007410186313712\n",
      "train loss:1.0082615270809823\n",
      "train loss:1.194140281435351\n",
      "train loss:0.9793762363067142\n",
      "train loss:0.942632978063929\n",
      "train loss:1.207420390362998\n",
      "train loss:1.0235595897981715\n",
      "train loss:0.9664782444051725\n",
      "train loss:1.13613663223269\n",
      "train loss:1.011648064121801\n",
      "train loss:1.059840216589868\n",
      "train loss:1.0295741934759244\n",
      "train loss:1.129227139342463\n",
      "train loss:1.139815145445261\n",
      "train loss:1.1115984854759964\n",
      "train loss:1.0022011778148703\n",
      "train loss:0.991293663046375\n",
      "train loss:1.0893449354992029\n",
      "train loss:1.098319369237293\n",
      "train loss:0.96879528863577\n",
      "train loss:1.1013222808211898\n",
      "train loss:1.171181070929574\n",
      "train loss:1.1633024561849619\n",
      "train loss:0.9622570567189745\n",
      "train loss:1.0329293476447172\n",
      "train loss:0.9620202397375143\n",
      "train loss:1.002029120800019\n",
      "train loss:0.9801556709661351\n",
      "train loss:1.1560805034928898\n",
      "train loss:1.0990425062002718\n",
      "train loss:1.1715958555084423\n",
      "train loss:0.9482786915740508\n",
      "train loss:1.1595550961694423\n",
      "train loss:1.0776871886689252\n",
      "train loss:1.332329666198586\n",
      "train loss:1.0799138834810846\n",
      "train loss:1.0966977623738363\n",
      "train loss:1.1593006929343135\n",
      "train loss:0.9546419144892626\n",
      "train loss:1.0994599129703224\n",
      "train loss:1.1590776648105576\n",
      "train loss:1.0176266646658687\n",
      "train loss:0.9729697907709629\n",
      "train loss:0.9778863121402851\n",
      "train loss:1.1756316364109158\n",
      "train loss:0.784873762804747\n",
      "train loss:0.9741482028444698\n",
      "train loss:1.1190460092067425\n",
      "train loss:0.8962993777404149\n",
      "train loss:1.0947967018145086\n",
      "train loss:1.1591799124403446\n",
      "train loss:1.1073030405553324\n",
      "train loss:0.883607445917513\n",
      "train loss:1.0441359006278472\n",
      "train loss:1.0813298326563812\n",
      "train loss:1.2303468155755852\n",
      "train loss:1.2045953849302584\n",
      "train loss:1.1433625058610586\n",
      "train loss:0.9414878988257785\n",
      "train loss:1.118368093543443\n",
      "train loss:1.110066409567155\n",
      "train loss:1.3417529222249516\n",
      "train loss:1.1522427126415753\n",
      "train loss:1.0731027622343994\n",
      "train loss:1.0862104680189497\n",
      "train loss:1.1678974344109003\n",
      "train loss:1.020048120523879\n",
      "train loss:1.1651793756209734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0817288205944333\n",
      "train loss:1.157835714677873\n",
      "train loss:0.8811047324124189\n",
      "train loss:1.1650816545857805\n",
      "train loss:0.8022972989738725\n",
      "train loss:1.0502727465155703\n",
      "train loss:1.1478607543448185\n",
      "train loss:1.0241344320641756\n",
      "train loss:0.9726591929468091\n",
      "train loss:1.264758125062088\n",
      "train loss:1.2311827079957316\n",
      "train loss:0.9389217874712221\n",
      "train loss:1.1045412453410288\n",
      "train loss:1.160899257440827\n",
      "train loss:0.9821629458192999\n",
      "train loss:1.2175670952635846\n",
      "train loss:1.1043340755292101\n",
      "train loss:0.9330890158663305\n",
      "train loss:1.071155386417582\n",
      "train loss:1.1478638055461792\n",
      "train loss:1.1396145713744479\n",
      "train loss:0.8674804176146509\n",
      "train loss:1.079553025328197\n",
      "train loss:1.1860895168590664\n",
      "train loss:0.9914730588987269\n",
      "train loss:1.034290653620059\n",
      "train loss:1.095160640791216\n",
      "train loss:0.862897671125737\n",
      "train loss:0.9336584214460146\n",
      "train loss:1.0367196854659277\n",
      "train loss:1.0788089885168595\n",
      "train loss:0.9709940914539237\n",
      "train loss:0.9439395859132723\n",
      "train loss:1.1189911088823892\n",
      "train loss:1.247613196781322\n",
      "train loss:0.905288356434382\n",
      "train loss:0.982228959338659\n",
      "train loss:1.2298884272997193\n",
      "train loss:1.2071329192822502\n",
      "train loss:1.0388481580658935\n",
      "train loss:1.104122032146133\n",
      "train loss:1.122077799335484\n",
      "train loss:0.8902129665970291\n",
      "train loss:0.9807000676996465\n",
      "train loss:1.0580994885313646\n",
      "train loss:1.0237106320206109\n",
      "train loss:0.9302212519783154\n",
      "train loss:1.0130550590744165\n",
      "train loss:1.0762175326905696\n",
      "train loss:1.1498976619709185\n",
      "train loss:1.207824766756374\n",
      "train loss:1.1892023428582383\n",
      "=== epoch:2, train acc:0.977, test acc:0.977 ===\n",
      "train loss:0.8520539790691136\n",
      "train loss:1.1477449025037096\n",
      "train loss:1.0971080597677667\n",
      "train loss:1.0081679925640583\n",
      "train loss:1.0148791365824037\n",
      "train loss:0.9170123597971037\n",
      "train loss:1.2520331169457275\n",
      "train loss:1.0960950055022385\n",
      "train loss:0.9943886379822204\n",
      "train loss:0.860805995942464\n",
      "train loss:1.2574965638955122\n",
      "train loss:1.024166797144538\n",
      "train loss:0.8466958889766096\n",
      "train loss:0.9727664107485592\n",
      "train loss:1.0881051793392973\n",
      "train loss:0.9566069335094194\n",
      "train loss:1.2484750738591501\n",
      "train loss:1.074793945701468\n",
      "train loss:1.1022301719835226\n",
      "train loss:1.250721539571437\n",
      "train loss:0.9610082997417467\n",
      "train loss:1.269884042547753\n",
      "train loss:1.1053773689339252\n",
      "train loss:1.11914571225833\n",
      "train loss:1.192351842757049\n",
      "train loss:0.8930086533853262\n",
      "train loss:1.05627681831115\n",
      "train loss:1.050620334096417\n",
      "train loss:1.2086134807385243\n",
      "train loss:1.09528427510288\n",
      "train loss:1.1658349971027244\n",
      "train loss:0.9421136276142684\n",
      "train loss:1.1180826150062522\n",
      "train loss:1.132488295358974\n",
      "train loss:1.0508001106313576\n",
      "train loss:1.0515072164256516\n",
      "train loss:1.030447534270606\n",
      "train loss:1.067874657776084\n",
      "train loss:1.1218118323082515\n",
      "train loss:0.973160634454875\n",
      "train loss:1.0319436530734931\n",
      "train loss:1.1316455415365954\n",
      "train loss:1.0326450248773085\n",
      "train loss:1.083001171318967\n",
      "train loss:1.0439492666268693\n",
      "train loss:0.9994723760745156\n",
      "train loss:0.9659488067460732\n",
      "train loss:1.0723663908992773\n",
      "train loss:0.9987084032636849\n",
      "train loss:1.0500578671063492\n",
      "train loss:0.9728575672492338\n",
      "train loss:1.1332849052001048\n",
      "train loss:0.8725166506224469\n",
      "train loss:0.9334288613037147\n",
      "train loss:1.1959662536056972\n",
      "train loss:1.2680722507176598\n",
      "train loss:1.065898154040142\n",
      "train loss:1.062432494112396\n",
      "train loss:0.9264321398285652\n",
      "train loss:1.000568727447545\n",
      "train loss:1.165098909523756\n",
      "train loss:1.0568115657829062\n",
      "train loss:0.9889364746865015\n",
      "train loss:0.9943126312887942\n",
      "train loss:1.0597621591878998\n",
      "train loss:1.0819198352529744\n",
      "train loss:1.0416687051537523\n",
      "train loss:1.1049291428152561\n",
      "train loss:1.3217890728837955\n",
      "train loss:1.1417521713546737\n",
      "train loss:1.0364528235571226\n",
      "train loss:1.0733887645750189\n",
      "train loss:0.9788271441617888\n",
      "train loss:0.9648853449842474\n",
      "train loss:1.1565356805135267\n",
      "train loss:0.9660479149492582\n",
      "train loss:1.0904483465460626\n",
      "train loss:1.1492648668553107\n",
      "train loss:1.0900703638612341\n",
      "train loss:1.1300517134802366\n",
      "train loss:1.1791198545445962\n",
      "train loss:0.9490433995696468\n",
      "train loss:0.929050052949319\n",
      "train loss:0.9649070770292666\n",
      "train loss:0.9792607739203336\n",
      "train loss:1.0845854181100427\n",
      "train loss:1.0145470126986091\n",
      "train loss:1.0575253832627152\n",
      "train loss:1.0538403114363555\n",
      "train loss:1.1000913723044037\n",
      "train loss:1.0443648152161682\n",
      "train loss:1.121320830541502\n",
      "train loss:1.1040308972094508\n",
      "train loss:1.0418881995198672\n",
      "train loss:1.0023685175310495\n",
      "train loss:0.978108768457862\n",
      "train loss:1.3450813567649365\n",
      "train loss:0.9980834051324318\n",
      "train loss:0.7088567202607404\n",
      "train loss:1.0497130941211457\n",
      "train loss:0.9819317771040462\n",
      "train loss:1.0670506596283535\n",
      "train loss:1.0532875434213411\n",
      "train loss:0.9425545170741172\n",
      "train loss:0.9184448141432598\n",
      "train loss:0.9969417027756181\n",
      "train loss:1.1356397447464623\n",
      "train loss:0.8505493268172012\n",
      "train loss:0.9259645155915486\n",
      "train loss:1.1205065621630192\n",
      "train loss:0.8404678517455434\n",
      "train loss:1.271887707141974\n",
      "train loss:1.1142754968920223\n",
      "train loss:1.12972072913312\n",
      "train loss:1.0569955072610135\n",
      "train loss:0.9823292167553755\n",
      "train loss:0.9417434099179427\n",
      "train loss:0.8461623310495449\n",
      "train loss:1.0886087964280744\n",
      "train loss:0.9787856202990656\n",
      "train loss:1.11803347125697\n",
      "train loss:1.035563394937736\n",
      "train loss:1.017877152083952\n",
      "train loss:1.1323827657140872\n",
      "train loss:1.0211646623313022\n",
      "train loss:0.9146555601055263\n",
      "train loss:1.1585486938743488\n",
      "train loss:0.9835706590119788\n",
      "train loss:1.1004587628440472\n",
      "train loss:1.0718517052898324\n",
      "train loss:1.0356386498638124\n",
      "train loss:0.9847472457100424\n",
      "train loss:1.0985166582748853\n",
      "train loss:1.0493476622919522\n",
      "train loss:0.9015096664764503\n",
      "train loss:1.0446971538361596\n",
      "train loss:0.9230137910220197\n",
      "train loss:1.2234324335305453\n",
      "train loss:1.064920004064573\n",
      "train loss:1.2221934180621803\n",
      "train loss:0.9626685629566638\n",
      "train loss:1.0891545652547427\n",
      "train loss:0.8633904745117136\n",
      "train loss:0.9879971612431463\n",
      "train loss:0.9878497709366633\n",
      "train loss:0.9708432834628065\n",
      "train loss:0.97831268650326\n",
      "train loss:0.9898148806957764\n",
      "train loss:0.9893427827166111\n",
      "train loss:0.9028237987573737\n",
      "train loss:0.8071604125567776\n",
      "train loss:1.0161273632708705\n",
      "train loss:1.2248023025732733\n",
      "train loss:1.0389185596722676\n",
      "train loss:0.9509988207926534\n",
      "train loss:1.0626001978330113\n",
      "train loss:0.9565406222270402\n",
      "train loss:0.9249900382595745\n",
      "train loss:1.0989287482467198\n",
      "train loss:1.1853410338118529\n",
      "train loss:1.0744623743966\n",
      "train loss:0.9941624702039843\n",
      "train loss:0.9231595298435287\n",
      "train loss:1.103193080549271\n",
      "train loss:1.2103704008653589\n",
      "train loss:1.158102561072899\n",
      "train loss:1.1494664735027516\n",
      "train loss:1.1206249961354227\n",
      "train loss:0.9599440085391291\n",
      "train loss:0.9692644005288206\n",
      "train loss:1.0176442303872915\n",
      "train loss:1.2229758898348841\n",
      "train loss:1.0816520776084366\n",
      "train loss:1.180514228891861\n",
      "train loss:0.9699675661587085\n",
      "train loss:0.947809027266841\n",
      "train loss:1.0373197529928746\n",
      "train loss:1.0406422547728669\n",
      "train loss:1.0520822266316205\n",
      "train loss:1.0450184017966313\n",
      "train loss:1.0013360888311984\n",
      "train loss:0.9929412542353885\n",
      "train loss:1.0248207289277906\n",
      "train loss:0.84016881024081\n",
      "train loss:0.8729120329183754\n",
      "train loss:1.1432996038102452\n",
      "train loss:0.9546473968602777\n",
      "train loss:1.0758869800164552\n",
      "train loss:1.0801628206072054\n",
      "train loss:1.087994698675929\n",
      "train loss:1.042480802702091\n",
      "train loss:0.9532265933175147\n",
      "train loss:0.879856836888089\n",
      "train loss:1.0567957949317366\n",
      "train loss:0.949791353962971\n",
      "train loss:0.9552966059734739\n",
      "train loss:0.9320627382961976\n",
      "train loss:0.7726228585721576\n",
      "train loss:1.1226271225617273\n",
      "train loss:0.909074552484916\n",
      "train loss:0.9306847228330334\n",
      "train loss:0.857658002305982\n",
      "train loss:1.011774536219096\n",
      "train loss:0.9796945118160157\n",
      "train loss:0.9570108934437609\n",
      "train loss:0.8462482189619689\n",
      "train loss:0.8287541285429789\n",
      "train loss:0.8356241583301884\n",
      "train loss:1.1333399189713969\n",
      "train loss:0.8365807918699797\n",
      "train loss:1.0770768024113602\n",
      "train loss:1.087908172250645\n",
      "train loss:1.01261179505266\n",
      "train loss:1.108314433492238\n",
      "train loss:0.9555078759996019\n",
      "train loss:1.0347752540804849\n",
      "train loss:0.9023429983404421\n",
      "train loss:1.1437687436872281\n",
      "train loss:0.8824187367975677\n",
      "train loss:0.9275654386787232\n",
      "train loss:0.99410344633674\n",
      "train loss:0.9535078028819164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1214408688590611\n",
      "train loss:1.0895330531379763\n",
      "train loss:0.9206601652426074\n",
      "train loss:1.0316810516178325\n",
      "train loss:0.8727547023321581\n",
      "train loss:0.8736100186071473\n",
      "train loss:0.8996896659181399\n",
      "train loss:1.0611327812506626\n",
      "train loss:0.91760520560464\n",
      "train loss:0.9560216143246326\n",
      "train loss:1.1393602490914392\n",
      "train loss:1.1963772134453203\n",
      "train loss:0.8724734921689948\n",
      "train loss:1.2047413645408733\n",
      "train loss:1.1308935810880199\n",
      "train loss:0.9303330628017358\n",
      "train loss:1.001015610392811\n",
      "train loss:0.8954577508083186\n",
      "train loss:1.045752485960596\n",
      "train loss:0.9511008493636193\n",
      "train loss:1.0172215547730703\n",
      "train loss:1.0635353104253067\n",
      "train loss:1.1299933695315398\n",
      "train loss:0.8012124322501347\n",
      "train loss:0.9431509650483162\n",
      "train loss:1.2723976332441485\n",
      "train loss:1.016693964443215\n",
      "train loss:1.0727100506439595\n",
      "train loss:0.9321938774496746\n",
      "train loss:0.9909088896453286\n",
      "train loss:1.0195913284548315\n",
      "train loss:1.2021222355902206\n",
      "train loss:0.8665152516239596\n",
      "train loss:1.041157922978653\n",
      "train loss:0.9585920709955255\n",
      "train loss:1.1167976730208227\n",
      "train loss:1.170563798457106\n",
      "train loss:0.772676404824044\n",
      "train loss:1.0713067363644635\n",
      "train loss:0.9815419781286562\n",
      "train loss:0.8984910518195859\n",
      "train loss:0.7636688583923175\n",
      "train loss:1.0095933649495838\n",
      "train loss:0.908811336856747\n",
      "train loss:1.1156250137023622\n",
      "train loss:0.9992649433160865\n",
      "train loss:0.8825880157570066\n",
      "train loss:1.0209207293066151\n",
      "train loss:0.8284922710485932\n",
      "train loss:1.0010152513336166\n",
      "train loss:0.9825765293018098\n",
      "train loss:0.9951542652616105\n",
      "train loss:0.8165948435395468\n",
      "train loss:1.192856942110181\n",
      "train loss:0.8752367104129717\n",
      "train loss:0.9670443402644301\n",
      "train loss:1.0278559635687303\n",
      "train loss:1.1590898106885907\n",
      "train loss:0.9490994307196972\n",
      "train loss:1.081848522466921\n",
      "train loss:1.0645788568821979\n",
      "train loss:1.017072860638617\n",
      "train loss:1.1057027713037895\n",
      "train loss:0.99584244917258\n",
      "train loss:1.1199566812462398\n",
      "train loss:1.1593020665635985\n",
      "train loss:1.0260681422978262\n",
      "train loss:0.9952612132071207\n",
      "train loss:1.0307467906986922\n",
      "train loss:1.0660133079924463\n",
      "train loss:1.012669380884326\n",
      "train loss:0.8163520566685263\n",
      "train loss:1.1675350557112172\n",
      "train loss:0.9254140804901031\n",
      "train loss:1.0305770750641596\n",
      "train loss:0.988801946414665\n",
      "train loss:1.0061418281141032\n",
      "train loss:1.1348477094396434\n",
      "train loss:0.9069673330640663\n",
      "train loss:1.1134118253513576\n",
      "train loss:1.0627381760888406\n",
      "train loss:1.153933713814643\n",
      "train loss:0.8296844578265785\n",
      "train loss:0.8577445301342174\n",
      "train loss:0.9929179889970983\n",
      "train loss:0.9210666981294812\n",
      "train loss:0.9145649140036761\n",
      "train loss:1.05486292776325\n",
      "train loss:0.9965455948809999\n",
      "train loss:1.0581316467017055\n",
      "train loss:1.1802207913256717\n",
      "train loss:0.9343506140833892\n",
      "train loss:1.1745701529577446\n",
      "train loss:1.034469620413968\n",
      "train loss:0.9604739440250732\n",
      "train loss:0.8923765664647069\n",
      "train loss:0.7835784049493233\n",
      "train loss:1.0944265837624052\n",
      "train loss:1.0290032250694072\n",
      "train loss:0.9795634679804774\n",
      "train loss:1.1317206176991392\n",
      "train loss:0.9487943263992455\n",
      "train loss:1.107743497338152\n",
      "train loss:0.9336076843907645\n",
      "train loss:1.061364088028438\n",
      "train loss:1.0186146953432438\n",
      "train loss:1.1164418160622558\n",
      "train loss:0.9762218770944107\n",
      "train loss:0.9742721028322192\n",
      "train loss:1.0704640913579722\n",
      "train loss:1.2512980343500475\n",
      "train loss:0.9652934078419798\n",
      "train loss:1.0264557841053177\n",
      "train loss:1.0964948459136719\n",
      "train loss:0.9484547211347477\n",
      "train loss:0.9750012204186814\n",
      "train loss:1.0716645529095743\n",
      "train loss:1.1429904607776582\n",
      "train loss:0.903443405426396\n",
      "train loss:0.8407733161558612\n",
      "train loss:1.024114298935518\n",
      "train loss:0.8322008476318677\n",
      "train loss:0.9991471155162834\n",
      "train loss:0.9614738974735575\n",
      "train loss:1.0477950611938196\n",
      "train loss:1.0664853007278396\n",
      "train loss:1.0900959777973314\n",
      "train loss:0.9784074615484364\n",
      "train loss:0.8663112015729447\n",
      "train loss:0.9432194836650959\n",
      "train loss:1.0646760133509645\n",
      "train loss:1.0656362219871136\n",
      "train loss:1.1479496734978172\n",
      "train loss:0.8699377176204223\n",
      "train loss:0.9742012993290191\n",
      "train loss:1.1421524574098492\n",
      "train loss:0.9600973831484028\n",
      "train loss:0.9570291343228835\n",
      "train loss:1.066119708536756\n",
      "train loss:1.1707244731951345\n",
      "train loss:0.9634629730997288\n",
      "train loss:1.0148245152090711\n",
      "train loss:0.975812656950166\n",
      "train loss:0.8910166585505638\n",
      "train loss:1.0869657713821959\n",
      "train loss:0.8948145460151502\n",
      "train loss:0.9558202979200737\n",
      "train loss:1.0799841470638691\n",
      "train loss:0.9938482450040647\n",
      "train loss:1.0761001753390311\n",
      "train loss:0.8608720554454679\n",
      "train loss:1.0643575849495166\n",
      "train loss:1.0144253817631776\n",
      "train loss:0.9841547291398058\n",
      "train loss:0.9393507576371579\n",
      "train loss:1.0224627268488298\n",
      "train loss:0.9614705694579248\n",
      "train loss:1.087092871633397\n",
      "train loss:1.0751149131207458\n",
      "train loss:0.9985294555406619\n",
      "train loss:1.0870626786733706\n",
      "train loss:0.9522099161125079\n",
      "train loss:0.9258925177689864\n",
      "train loss:0.9038242673272247\n",
      "train loss:0.7999452012118518\n",
      "train loss:0.9949612097645306\n",
      "train loss:0.9718238493278539\n",
      "train loss:0.888382548089424\n",
      "train loss:0.8724679597366419\n",
      "train loss:1.1347388479028375\n",
      "train loss:1.0399013718965455\n",
      "train loss:0.976713384331243\n",
      "train loss:0.9153401157721727\n",
      "train loss:1.0681785873670047\n",
      "train loss:0.9192339241440899\n",
      "train loss:0.9357923341003642\n",
      "train loss:1.0757361864145947\n",
      "train loss:0.9074933392205128\n",
      "train loss:1.2122740302460089\n",
      "train loss:1.0084697129147504\n",
      "train loss:0.9805075251325411\n",
      "train loss:0.9438861122838341\n",
      "train loss:0.8995054463352598\n",
      "train loss:0.9633001378302126\n",
      "train loss:0.9498032550920726\n",
      "train loss:0.9887139182120608\n",
      "train loss:1.1169281293557514\n",
      "train loss:1.10286827290903\n",
      "train loss:0.9709866890000649\n",
      "train loss:1.0271173189365972\n",
      "train loss:0.989884886735445\n",
      "train loss:0.9735218890593194\n",
      "train loss:0.8238842632552177\n",
      "train loss:0.9665641513153286\n",
      "train loss:1.0546550564933908\n",
      "train loss:0.987132207153701\n",
      "train loss:0.9195071129433363\n",
      "train loss:0.8763899877553664\n",
      "train loss:1.1293292596397964\n",
      "train loss:1.047509219492199\n",
      "train loss:0.9040501950138164\n",
      "train loss:0.7868041978049125\n",
      "train loss:0.9352106608659467\n",
      "train loss:1.0211139213452214\n",
      "train loss:0.9842039732283445\n",
      "train loss:0.8254451741291352\n",
      "train loss:1.0610412540492222\n",
      "train loss:0.9302128170066237\n",
      "train loss:0.9060794765564555\n",
      "train loss:0.9513529706699125\n",
      "train loss:1.0205897056992361\n",
      "train loss:0.8889546582044909\n",
      "train loss:1.0459867824321858\n",
      "train loss:1.1119920784856794\n",
      "train loss:1.0806617818003657\n",
      "train loss:1.0615708079152821\n",
      "train loss:1.08714315000593\n",
      "train loss:1.0167063807767704\n",
      "train loss:0.8755213682817872\n",
      "train loss:1.0410650519189508\n",
      "train loss:1.0317729413125911\n",
      "train loss:0.8657134658398506\n",
      "train loss:1.0565859837333844\n",
      "train loss:1.0106665837474131\n",
      "train loss:0.9223616769522898\n",
      "train loss:0.9992568557958016\n",
      "train loss:0.9234400348640405\n",
      "train loss:1.1643707038161362\n",
      "train loss:1.1105875027539462\n",
      "train loss:0.9011268491879489\n",
      "train loss:1.144271918364853\n",
      "train loss:1.0497261930874613\n",
      "train loss:1.0189188886558884\n",
      "train loss:0.9660549696318451\n",
      "train loss:1.2256138201112423\n",
      "train loss:1.0222190672048195\n",
      "train loss:0.8272499606364225\n",
      "train loss:0.9953488663404305\n",
      "train loss:1.1795290037794062\n",
      "train loss:0.8554238020076891\n",
      "train loss:0.9527126900950392\n",
      "train loss:1.1116609933676755\n",
      "train loss:1.0182090570518885\n",
      "train loss:1.0530236797036516\n",
      "train loss:1.1101433942383172\n",
      "train loss:1.0298677498515516\n",
      "train loss:0.9578681355747862\n",
      "train loss:1.0314828678082724\n",
      "train loss:0.7320338807509998\n",
      "train loss:0.8765623077166202\n",
      "train loss:0.9509888679530343\n",
      "train loss:1.0033619958254498\n",
      "train loss:0.9859186230692306\n",
      "train loss:0.9017373664865983\n",
      "train loss:0.8287321994226717\n",
      "train loss:0.9628264179871294\n",
      "train loss:1.028333962072022\n",
      "train loss:0.8856491654240846\n",
      "train loss:0.8200341510530685\n",
      "train loss:0.9259591114912961\n",
      "train loss:0.9844674633623066\n",
      "train loss:0.9378499870807231\n",
      "train loss:1.0014783100010403\n",
      "train loss:0.9725360179382094\n",
      "train loss:0.9323627742248144\n",
      "train loss:0.8255655928741994\n",
      "train loss:1.0931552612327693\n",
      "train loss:1.1597923923368292\n",
      "train loss:1.0129049294633918\n",
      "train loss:1.1491392727397325\n",
      "train loss:0.9041083276615568\n",
      "train loss:0.7733608120363472\n",
      "train loss:0.958772994945854\n",
      "train loss:0.8882623228746475\n",
      "train loss:0.9333907674332963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.975959834826996\n",
      "train loss:0.8800416299912954\n",
      "train loss:0.901755416633225\n",
      "train loss:1.0003444786516187\n",
      "train loss:0.8872622191261337\n",
      "train loss:1.0116016224145292\n",
      "train loss:1.1054993942705413\n",
      "train loss:1.086019422661473\n",
      "train loss:0.8107519785335375\n",
      "train loss:0.9602630605553216\n",
      "train loss:0.9357748612337063\n",
      "train loss:1.0694895003980165\n",
      "train loss:1.0897571324647648\n",
      "train loss:1.0633324529142174\n",
      "train loss:1.194670776538924\n",
      "train loss:0.9728472252300806\n",
      "train loss:1.0414783999472585\n",
      "train loss:0.9695561741443361\n",
      "train loss:0.9105517436661974\n",
      "train loss:0.9000848443049443\n",
      "train loss:1.0670471445661283\n",
      "train loss:0.897787844931529\n",
      "train loss:1.1051648674897063\n",
      "train loss:0.9253237834411091\n",
      "train loss:1.0008022602366828\n",
      "train loss:1.1055321953440025\n",
      "train loss:1.02360429144147\n",
      "train loss:1.0852267444764339\n",
      "train loss:1.1116690779510396\n",
      "train loss:1.0560859371899125\n",
      "train loss:0.9277330620696245\n",
      "train loss:1.1223230745782429\n",
      "train loss:1.0381538959278256\n",
      "train loss:1.0876231189199508\n",
      "train loss:0.9356812325713482\n",
      "train loss:1.037120369337473\n",
      "train loss:1.017080702256991\n",
      "train loss:0.8125515070649415\n",
      "train loss:0.9291957099837633\n",
      "train loss:1.0934882166912119\n",
      "train loss:1.0566463194986802\n",
      "train loss:0.8535160885402111\n",
      "train loss:0.9589021970544823\n",
      "train loss:1.1590659819906817\n",
      "train loss:1.0175451374464228\n",
      "train loss:0.9777216558275513\n",
      "train loss:1.0014699777010498\n",
      "train loss:0.9747067613918443\n",
      "train loss:0.9589113916017462\n",
      "train loss:0.9673238377747634\n",
      "train loss:1.0298313653982893\n",
      "train loss:0.9053113457561639\n",
      "train loss:0.9168110222182139\n",
      "train loss:0.9360890652220485\n",
      "train loss:1.0007645335212931\n",
      "train loss:1.1356818128712878\n",
      "train loss:1.0684580466022686\n",
      "train loss:1.0103593519479654\n",
      "train loss:0.8752231797817287\n",
      "train loss:0.934042994438874\n",
      "train loss:1.1448092097885612\n",
      "train loss:0.9715158056614421\n",
      "train loss:0.8105791143650117\n",
      "train loss:0.9678068547977584\n",
      "train loss:0.8570973477266844\n",
      "train loss:0.8473787444945091\n",
      "train loss:0.8081855344677331\n",
      "train loss:0.8183290480638942\n",
      "train loss:1.0664672324033888\n",
      "train loss:1.1941372272629625\n",
      "train loss:0.9957878977864874\n",
      "train loss:0.8573420662220479\n",
      "train loss:1.0718874366050997\n",
      "train loss:1.0128757861171374\n",
      "train loss:1.0676541730027913\n",
      "train loss:1.069987423382714\n",
      "train loss:1.0645473197051993\n",
      "train loss:0.9954514416588915\n",
      "train loss:0.9809811057537879\n",
      "train loss:1.0627594978102295\n",
      "train loss:0.9065490363778385\n",
      "train loss:0.8992632652346205\n",
      "train loss:1.113923250946295\n",
      "train loss:0.8662167506552012\n",
      "train loss:0.8964439464670463\n",
      "train loss:0.874322879671879\n",
      "train loss:1.00855290718874\n",
      "train loss:1.078203611420897\n",
      "train loss:0.9697303757284171\n",
      "train loss:1.1173486635368155\n",
      "train loss:1.0217658407406924\n",
      "train loss:1.1397667124975337\n",
      "train loss:0.8851648446321485\n",
      "train loss:0.9901139602154377\n",
      "train loss:0.8615937918724781\n",
      "train loss:0.8589020467060955\n",
      "train loss:0.8307202979672154\n",
      "train loss:0.8644966663219321\n",
      "train loss:1.163663743856225\n",
      "train loss:0.8979718249202251\n",
      "train loss:0.9567321372121994\n",
      "train loss:0.9922196171733673\n",
      "train loss:1.0393901766623617\n",
      "=== epoch:3, train acc:0.984, test acc:0.988 ===\n",
      "train loss:0.8655808973908963\n",
      "train loss:0.7119342939204871\n",
      "train loss:0.7663033039465094\n",
      "train loss:0.8529990996152971\n",
      "train loss:0.9269447544845008\n",
      "train loss:1.0015563398156713\n",
      "train loss:0.9596397590416013\n",
      "train loss:0.9420801680063805\n",
      "train loss:0.7414243361168907\n",
      "train loss:1.0555770296915292\n",
      "train loss:1.0650261479912553\n",
      "train loss:0.9225497245336437\n",
      "train loss:1.118333452479359\n",
      "train loss:0.8181341934376793\n",
      "train loss:0.8532572259232863\n",
      "train loss:1.0613519560614089\n",
      "train loss:0.9888238410659652\n",
      "train loss:0.9981021254502842\n",
      "train loss:0.7782290481842018\n",
      "train loss:1.0798743920583265\n",
      "train loss:0.986373257590451\n",
      "train loss:1.0962702370184105\n",
      "train loss:1.127234585559287\n",
      "train loss:1.0681618884658877\n",
      "train loss:0.949429870899202\n",
      "train loss:0.898510332348728\n",
      "train loss:0.8538642904623284\n",
      "train loss:0.9641838279865584\n",
      "train loss:0.9248616802175478\n",
      "train loss:0.9483008840563908\n",
      "train loss:1.213738932340952\n",
      "train loss:1.0056498839639831\n",
      "train loss:0.920247922770946\n",
      "train loss:1.0107087501832774\n",
      "train loss:1.0762616201052244\n",
      "train loss:0.8351770946341786\n",
      "train loss:0.9970065113158756\n",
      "train loss:0.9928765567914654\n",
      "train loss:0.9544650286148196\n",
      "train loss:1.0840309220094435\n",
      "train loss:1.0137943458091054\n",
      "train loss:1.095936271689058\n",
      "train loss:1.0190412206885469\n",
      "train loss:0.9874121076346684\n",
      "train loss:0.9594732531742934\n",
      "train loss:0.9611067168347318\n",
      "train loss:1.0025210814709284\n",
      "train loss:0.8669235299199461\n",
      "train loss:0.9039550533675971\n",
      "train loss:0.9111767793261961\n",
      "train loss:1.0367824398330026\n",
      "train loss:1.0931950588254016\n",
      "train loss:0.9186505091438159\n",
      "train loss:1.2068077948918121\n",
      "train loss:0.9873820855816723\n",
      "train loss:0.9210684403760157\n",
      "train loss:0.9615957755634831\n",
      "train loss:0.9396506933107152\n",
      "train loss:0.9733788540515498\n",
      "train loss:0.9730902314710099\n",
      "train loss:1.0220843277536207\n",
      "train loss:1.0675263904149324\n",
      "train loss:0.9981653442682114\n",
      "train loss:1.0679518383742883\n",
      "train loss:0.8143545176614428\n",
      "train loss:0.9328140824198943\n",
      "train loss:0.8827458029892884\n",
      "train loss:0.9857616058814692\n",
      "train loss:1.0056774527419223\n",
      "train loss:0.715607306132492\n",
      "train loss:1.0104573254406142\n",
      "train loss:0.9931965732308338\n",
      "train loss:0.8218037589277195\n",
      "train loss:0.9321194765336936\n",
      "train loss:0.8790080885078523\n",
      "train loss:0.9294815600680508\n",
      "train loss:0.9367120690088528\n",
      "train loss:0.9526227030348585\n",
      "train loss:1.0298680964137596\n",
      "train loss:0.9693656781681389\n",
      "train loss:1.0678189207403155\n",
      "train loss:0.8605913338955493\n",
      "train loss:1.1075868523046999\n",
      "train loss:1.036546208209716\n",
      "train loss:0.9126634056151903\n",
      "train loss:0.9571653723941609\n",
      "train loss:0.9109182169082187\n",
      "train loss:1.0507287778242285\n",
      "train loss:1.1839515894581216\n",
      "train loss:1.0538119011262121\n",
      "train loss:0.9289102362596003\n",
      "train loss:0.9087830264048758\n",
      "train loss:1.0080719913041678\n",
      "train loss:1.0143538228761801\n",
      "train loss:0.8923861158157784\n",
      "train loss:0.9212240532013122\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  #       \n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from deep_conv import DeepConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=20, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "#  \n",
    "network.save_params(\"deep_convnet_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3f8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
