{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b1e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# 계산그래프\n",
    "\n",
    "# 계산 과정을 그래프로 나타낸 것. node와 edge 활용\n",
    "# 각 node에는 연산 내용을, edge에는 계산 결과를 적어 보냄\n",
    "# 계산 그래프를 구성해 순방향으로 계산하는것이 순전파, 거꾸로 돌아가는게 역전파\n",
    "\n",
    "# 계산그래프는 각 node의 연산만을 신경쓰면 되므로 아주 작은 단위로 계산을 쪼개게 된다\n",
    "# 따라서 역전파를 이용해 미분을 효율적으로 계산할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ca3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연쇄법칙\n",
    "\n",
    "# 합성함수의 미분에 대한 성질\n",
    "# 국소적인 미분(편미분)을 곱해 연쇄법칙에 따라 역방향으로 전달\n",
    "# 변수 x y를 좌측에 두고 오른쪽으로 합성해 만든 함수 z가 존재할 때 x 변화량에 따른 z 변화량은 z부터 x로 거슬러 올라가는 것으로 계산됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3fc5aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n",
      "2.2 110 200\n"
     ]
    }
   ],
   "source": [
    "#곱셈계층 구현\n",
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        \n",
    "        return out\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y #x와y 바꿈\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy\n",
    "\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(price)\n",
    "print(dapple, int(dapple_num), dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b0fe87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "2.2 110\n",
      "3.3000000000000003 165\n",
      "650\n"
     ]
    }
   ],
   "source": [
    "#덧셈계층 구현\n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "\n",
    "        return dx, dy\n",
    "\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)  # (1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)  # (2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)\n",
    "price = mul_tax_layer.forward(all_price, tax)  # (4)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)  # (4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)  # (2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)  # (1)\n",
    "\n",
    "print(price)\n",
    "print(dapple, int(dapple_num))\n",
    "print(dorange, int(dorange_num))\n",
    "print(dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5bec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "# 활성화 함수 계층 구현\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx\n",
    "    \n",
    "x = np.array([[1.0, -0.5],[-2.0, 3.0]])\n",
    "mask = (x <= 0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f453eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid 계층 구현\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx\n",
    "    \n",
    "#Affine (순전파 행렬곱) 계층 구현\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b295bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Softmax with Loss 계층\n",
    "#교차 엔트로피 오차\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None #손실\n",
    "        self.y = None # softmax 출력\n",
    "        self.t = None # 정답 레이블(원-핫 벡터)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af330119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#오차역전파법 구현\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict #순서가 있는 Dictionary\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x:입력 데이터, t:정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        # 순전파\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc9fa842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:3.931532522123794e-10\n",
      "b1:2.1847652910259898e-09\n",
      "W2:6.5708121833305854e-09\n",
      "b2:1.399459751291743e-07\n"
     ]
    }
   ],
   "source": [
    "#기울기 확인\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
    "    print(key + \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0edbaf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15668333333333334 0.1677\n",
      "0.9023333333333333 0.9071\n",
      "0.9231333333333334 0.927\n",
      "0.9352666666666667 0.9336\n",
      "0.94545 0.9441\n",
      "0.9523833333333334 0.9509\n",
      "0.9557 0.953\n",
      "0.9609833333333333 0.9569\n",
      "0.9649333333333333 0.9605\n",
      "0.9669166666666666 0.9613\n",
      "0.9696666666666667 0.9644\n",
      "0.9711 0.964\n",
      "0.9739 0.9661\n",
      "0.9739 0.9673\n",
      "0.9770833333333333 0.9682\n",
      "0.9778166666666667 0.9677\n",
      "0.9788166666666667 0.9687\n"
     ]
    }
   ],
   "source": [
    "#오차역전법을 활용한 학습 구현\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 오차역전법으로 기울기 계산\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bcede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
